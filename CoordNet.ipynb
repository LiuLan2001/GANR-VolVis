{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65132e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.join('.', 'code'))   \n",
    "from utils import BatchIndex,get_mgrid,fast_random_choice,count_params,cleanup,seed_everything,dataset_selection,adjust_lr\n",
    "from load_data_INR import LoadData\n",
    "from model_INR import CoordNet,CoordNetBottleNeck,NGPNet,HashCoordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad143eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import threading\n",
    "import queue\n",
    "import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "class ScalarDataSet(LoadData):\n",
    "    def __init__(self,args, device='cuda:0'):\n",
    "        self.dataset, self.batch_size = args.dataset, args.batch_size\n",
    "        self.temporal, self.spatial = args.temporal, args.spatial\n",
    "        self.device = device        \n",
    "        self.ori_dim, self.total_samples, self.data_path, self.downsample_factor = dataset_selection(self.dataset,self.spatial, \n",
    "                                                                                                     self.temporal)\n",
    "        self.dim = [0,0,0]    \n",
    "        for i in range(len(self.ori_dim)):\n",
    "            self.dim[i] = int(self.ori_dim[i] / self.spatial)\n",
    "\n",
    "        self.num_workers = 16\n",
    "\n",
    "        self.samples = [i for i in range(1,self.total_samples+1,self.temporal+1)]\n",
    "        self.total_samples = self.samples[-1]\n",
    "        self.num_samples_per_frame = (self.dim[0]*self.dim[1]*self.dim[2]//self.downsample_factor)//self.batch_size * self.batch_size\n",
    "\n",
    "        self.queue_size = 2\n",
    "        self.loader_queue = queue.Queue(maxsize=self.queue_size)  # 限制队列大小为2\n",
    "        self.executor = ThreadPoolExecutor(max_workers=self.queue_size)\n",
    "\n",
    "        if args.mode == 'train':\n",
    "            self.data = self.preload_with_multi_threads(self.load_volume_data, num_workers=self.num_workers, data_str='Volume Data')\n",
    "            self.data = torch.as_tensor(np.asarray(self.data), device=self.device)  # [t个时间步, z, y, x] 需要改成xyz的形式\n",
    "\n",
    "            self.len = self.num_samples_per_frame * len(self.samples)\n",
    "            self._get_data = self._get_training_data\n",
    "\n",
    "        samples = self.ori_dim[2]*self.ori_dim[1]*self.ori_dim[0]\n",
    "        self.coords = get_mgrid([self.ori_dim[0],self.ori_dim[1],self.ori_dim[2]],dim=3)\n",
    "        self.time = np.zeros((samples,1))\n",
    "        self.testing_data_inputs = torch.as_tensor(np.concatenate((self.time, self.coords),axis=1), dtype=torch.float, device='cuda:0')\n",
    "        self.preload_data()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _get_training_data(self):\n",
    "        training_data_inputs = []\n",
    "        training_data_outputs = []\n",
    "\n",
    "        for i in range(0, len(self.samples)):\n",
    "            x,y,z = fast_random_choice(self.dim, self.num_samples_per_frame)\n",
    "            t = torch.ones_like(x) * (self.samples[i]-1)\n",
    "\n",
    "            outputs = self.data[i, x, y, z]  # 第i个体数据中取xyz, 第i个体数据对应的时间步是t\n",
    "            # 归一化\n",
    "\n",
    "            x = x * self.spatial / (self.ori_dim[0] - 1)  #x / (self.dim[0] - 1)\n",
    "            y = y * self.spatial / (self.ori_dim[1] - 1)  #y / (self.dim[1] - 1)\n",
    "            z = z * self.spatial / (self.ori_dim[2] - 1)  #z / (self.dim[2] - 1)\n",
    "            t = t / max((self.total_samples-1), 1)\n",
    "\n",
    "            inputs = torch.stack([t, x, y, z], dim=-1)\n",
    "            inputs = 2.0 * inputs - 1.0  # 缩放到[-1,1]\n",
    "            training_data_inputs.append(inputs)\n",
    "            training_data_outputs.append(outputs)\n",
    "\n",
    "        training_data_inputs = torch.cat(training_data_inputs, dim=0).cuda()\n",
    "        training_data_outputs = torch.cat(training_data_outputs, dim=0).cuda()\n",
    "        idx = torch.randperm(training_data_inputs.shape[0], device='cpu')\n",
    "        training_data_inputs = training_data_inputs[idx].contiguous()\n",
    "        training_data_outputs = training_data_outputs[idx].contiguous()\n",
    "        batchidxgenerator = BatchIndex(self.len, self.batch_size, shuffle=True)\n",
    "        del idx\n",
    "        cleanup()\n",
    "        return training_data_inputs, training_data_outputs, batchidxgenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f11e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "from datetime import datetime\n",
    "from shutil import copy, copytree\n",
    "import json\n",
    "import time\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import math\n",
    "\n",
    "def trainNet(model,args,dataset):\n",
    "    result_dir = os.path.join(args.result_dir, f'{args.dataset}', f'CoordNet')\n",
    "\n",
    "    checkpoints_dir = os.path.join(result_dir, 'checkpoints')\n",
    "    outputs_dir = os.path.join(result_dir, 'outputs')\n",
    "    os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "    os.makedirs(outputs_dir, exist_ok=True)\n",
    "    \n",
    "    loss_log_file = result_dir+'/'+'loss.txt'\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr, betas=(0.9,0.999), weight_decay=1e-6, fused=True)\n",
    "    mse_loss = nn.MSELoss()\n",
    "    scaler = GradScaler(enabled=args.fp16)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for epoch in range(1,args.num_epochs+1):\n",
    "        model.train()\n",
    "        training_data_inputs, training_data_outputs, batchIndexGenerator = dataset.get_data()\n",
    "        loss_mse = 0\n",
    "        loss_grad = 0\n",
    "        loop = tqdm.tqdm(batchIndexGenerator)\n",
    "\n",
    "        for current_idx, next_idx in loop:\n",
    "            coord = training_data_inputs[current_idx:next_idx].contiguous()\n",
    "            v = training_data_outputs[current_idx:next_idx].contiguous()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast(enabled=args.fp16):\n",
    "                v_pred = model(coord)\n",
    "                loss = mse_loss(v_pred.view(-1),v.view(-1))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            loss_mse += loss.mean().item()\n",
    "\n",
    "            loop.set_description(f'Epoch [{epoch}/{args.num_epochs}]')\n",
    "            loop.set_postfix(loss=loss_mse)\n",
    "        adjust_lr(args, optimizer, epoch)\n",
    "        # scheduler.step()\n",
    "\n",
    "        with open(loss_log_file,\"a\") as f:\n",
    "            f.write(f\"Epochs {epoch}: loss = {loss_mse}, lr = {optimizer.param_groups[0]['lr']}\")\n",
    "            f.write('\\n')\n",
    "\n",
    "        if epoch%args.checkpoint == 0 or epoch == 1:\n",
    "            torch.save(model.state_dict(),checkpoints_dir+'/'+'-'+str(args.spatial)+'-'+str(args.temporal)+'-'+str(epoch)+'.pth')\n",
    "    with open(loss_log_file,\"a\") as f:\n",
    "        f.write(f\"time:{time.time()-start_time}\")\n",
    "        f.write('\\n')\n",
    "\n",
    "@torch.no_grad()\n",
    "def inf(model,dataset,args, result_dir=None):\n",
    "    ckpt = './result/'+args.dataset+args.ckpt+'-'+str(args.spatial)+'-'+str(args.temporal)+'-'+str(args.num_epochs)+'.pth'\n",
    "    result_dir = os.path.dirname(os.path.dirname(ckpt)) if result_dir is None else result_dir\n",
    "    outputs_dir = os.path.join(result_dir, 'outputs', str(args.spatial)+'-'+str(args.temporal))\n",
    "    os.makedirs(outputs_dir, exist_ok=True)\n",
    "\n",
    "    model.eval()\n",
    "    samples = dataset.samples\n",
    "    for i in range(len(samples)):  \n",
    "        for j in range(0,dataset.temporal+1):\n",
    "            frame_idx = samples[i] + j\n",
    "            val_data_inputs, batchIndexGenerator =dataset._get_testing_data(frame_idx)\n",
    "            d = []\n",
    "            loop = tqdm.tqdm(batchIndexGenerator)\n",
    "            for current_idx, next_idx in loop:\n",
    "                coord = val_data_inputs[current_idx:next_idx]\n",
    "                with torch.no_grad():\n",
    "                    dat = model(coord).view(-1)\n",
    "                    d.append(dat)\n",
    "            d = torch.cat(d,dim=-1).float()\n",
    "            d = d.detach().cpu().numpy()\n",
    "            d = np.asarray(d,dtype='<f')\n",
    "            out_path = f'{outputs_dir}/{frame_idx:04}-CoordNet.raw'\n",
    "            d.tofile(out_path, format='<f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c04af3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP16 enbled:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initalize Model Successfully using Sine Function!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_1228\\1958929242.py:26: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=args.fp16)\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_1228\\1958929242.py:41: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=args.fp16):\n",
      "Epoch [1/100]: 100%|██████████| 32/32 [00:00<00:00, 44.81it/s, loss=10.2]\n",
      "Epoch [2/100]: 100%|██████████| 32/32 [00:00<00:00, 63.13it/s, loss=5.25]\n",
      "Epoch [3/100]: 100%|██████████| 32/32 [00:00<00:00, 63.24it/s, loss=3.75]\n",
      "Epoch [4/100]: 100%|██████████| 32/32 [00:00<00:00, 62.70it/s, loss=2.79]\n",
      "Epoch [5/100]: 100%|██████████| 32/32 [00:00<00:00, 64.06it/s, loss=2.21] \n",
      "Epoch [6/100]: 100%|██████████| 32/32 [00:00<00:00, 62.58it/s, loss=1.94] \n",
      "Epoch [7/100]: 100%|██████████| 32/32 [00:00<00:00, 63.81it/s, loss=1.83] \n",
      "Epoch [8/100]: 100%|██████████| 32/32 [00:00<00:00, 63.68it/s, loss=1.76] \n",
      "Epoch [9/100]: 100%|██████████| 32/32 [00:00<00:00, 63.04it/s, loss=1.71] \n",
      "Epoch [10/100]: 100%|██████████| 32/32 [00:00<00:00, 63.40it/s, loss=1.56] \n",
      "Epoch [11/100]: 100%|██████████| 32/32 [00:00<00:00, 64.05it/s, loss=1.42] \n",
      "Epoch [12/100]: 100%|██████████| 32/32 [00:00<00:00, 63.66it/s, loss=1.34] \n",
      "Epoch [13/100]: 100%|██████████| 32/32 [00:00<00:00, 63.10it/s, loss=1.29] \n",
      "Epoch [14/100]: 100%|██████████| 32/32 [00:00<00:00, 62.47it/s, loss=1.06] \n",
      "Epoch [15/100]: 100%|██████████| 32/32 [00:00<00:00, 63.14it/s, loss=0.92] \n",
      "Epoch [16/100]: 100%|██████████| 32/32 [00:00<00:00, 63.42it/s, loss=0.714]\n",
      "Epoch [17/100]: 100%|██████████| 32/32 [00:00<00:00, 63.58it/s, loss=0.574]\n",
      "Epoch [18/100]: 100%|██████████| 32/32 [00:00<00:00, 63.36it/s, loss=0.5]  \n",
      "Epoch [19/100]: 100%|██████████| 32/32 [00:00<00:00, 63.45it/s, loss=0.381]\n",
      "Epoch [20/100]: 100%|██████████| 32/32 [00:00<00:00, 65.09it/s, loss=0.348]\n",
      "Epoch [21/100]: 100%|██████████| 32/32 [00:00<00:00, 64.87it/s, loss=0.296]\n",
      "Epoch [22/100]: 100%|██████████| 32/32 [00:00<00:00, 65.47it/s, loss=0.229] \n",
      "Epoch [23/100]: 100%|██████████| 32/32 [00:00<00:00, 65.40it/s, loss=0.207] \n",
      "Epoch [24/100]: 100%|██████████| 32/32 [00:00<00:00, 64.79it/s, loss=0.172] \n",
      "Epoch [25/100]: 100%|██████████| 32/32 [00:00<00:00, 64.91it/s, loss=0.167] \n",
      "Epoch [26/100]: 100%|██████████| 32/32 [00:00<00:00, 64.72it/s, loss=0.135] \n",
      "Epoch [27/100]: 100%|██████████| 32/32 [00:00<00:00, 64.65it/s, loss=0.122] \n",
      "Epoch [28/100]: 100%|██████████| 32/32 [00:00<00:00, 61.13it/s, loss=0.104] \n",
      "Epoch [29/100]: 100%|██████████| 32/32 [00:00<00:00, 64.43it/s, loss=0.0949]\n",
      "Epoch [30/100]: 100%|██████████| 32/32 [00:00<00:00, 63.84it/s, loss=0.0875]\n",
      "Epoch [31/100]: 100%|██████████| 32/32 [00:00<00:00, 64.19it/s, loss=0.0858]\n",
      "Epoch [32/100]: 100%|██████████| 32/32 [00:00<00:00, 64.87it/s, loss=0.0797]\n",
      "Epoch [33/100]: 100%|██████████| 32/32 [00:00<00:00, 65.16it/s, loss=0.0618]\n",
      "Epoch [34/100]: 100%|██████████| 32/32 [00:00<00:00, 63.99it/s, loss=0.0566]\n",
      "Epoch [35/100]: 100%|██████████| 32/32 [00:00<00:00, 65.56it/s, loss=0.0522]\n",
      "Epoch [36/100]: 100%|██████████| 32/32 [00:00<00:00, 64.92it/s, loss=0.0478]\n",
      "Epoch [37/100]: 100%|██████████| 32/32 [00:00<00:00, 64.39it/s, loss=0.0519]\n",
      "Epoch [38/100]: 100%|██████████| 32/32 [00:00<00:00, 64.38it/s, loss=0.0412]\n",
      "Epoch [39/100]: 100%|██████████| 32/32 [00:00<00:00, 63.35it/s, loss=0.038] \n",
      "Epoch [40/100]: 100%|██████████| 32/32 [00:00<00:00, 63.55it/s, loss=0.0371]\n",
      "Epoch [41/100]: 100%|██████████| 32/32 [00:00<00:00, 64.27it/s, loss=0.033] \n",
      "Epoch [42/100]: 100%|██████████| 32/32 [00:00<00:00, 63.63it/s, loss=0.0308]\n",
      "Epoch [43/100]: 100%|██████████| 32/32 [00:00<00:00, 63.36it/s, loss=0.0303]\n",
      "Epoch [44/100]: 100%|██████████| 32/32 [00:00<00:00, 64.20it/s, loss=0.0298]\n",
      "Epoch [45/100]: 100%|██████████| 32/32 [00:00<00:00, 62.56it/s, loss=0.0275] \n",
      "Epoch [46/100]: 100%|██████████| 32/32 [00:00<00:00, 62.57it/s, loss=0.025]  \n",
      "Epoch [47/100]: 100%|██████████| 32/32 [00:00<00:00, 63.42it/s, loss=0.0237] \n",
      "Epoch [48/100]: 100%|██████████| 32/32 [00:00<00:00, 62.32it/s, loss=0.0219] \n",
      "Epoch [49/100]: 100%|██████████| 32/32 [00:00<00:00, 61.66it/s, loss=0.0215] \n",
      "Epoch [50/100]: 100%|██████████| 32/32 [00:00<00:00, 61.88it/s, loss=0.0212] \n",
      "Epoch [51/100]: 100%|██████████| 32/32 [00:00<00:00, 61.61it/s, loss=0.0199] \n",
      "Epoch [52/100]: 100%|██████████| 32/32 [00:00<00:00, 61.91it/s, loss=0.019]  \n",
      "Epoch [53/100]: 100%|██████████| 32/32 [00:00<00:00, 62.09it/s, loss=0.0189] \n",
      "Epoch [54/100]: 100%|██████████| 32/32 [00:00<00:00, 63.51it/s, loss=0.0173] \n",
      "Epoch [55/100]: 100%|██████████| 32/32 [00:00<00:00, 63.08it/s, loss=0.0168] \n",
      "Epoch [56/100]: 100%|██████████| 32/32 [00:00<00:00, 62.39it/s, loss=0.0157] \n",
      "Epoch [57/100]: 100%|██████████| 32/32 [00:00<00:00, 63.06it/s, loss=0.0152] \n",
      "Epoch [58/100]: 100%|██████████| 32/32 [00:00<00:00, 64.19it/s, loss=0.0149] \n",
      "Epoch [59/100]: 100%|██████████| 32/32 [00:00<00:00, 63.75it/s, loss=0.0142] \n",
      "Epoch [60/100]: 100%|██████████| 32/32 [00:00<00:00, 62.88it/s, loss=0.0137] \n",
      "Epoch [61/100]: 100%|██████████| 32/32 [00:00<00:00, 63.67it/s, loss=0.0136] \n",
      "Epoch [62/100]: 100%|██████████| 32/32 [00:00<00:00, 63.43it/s, loss=0.0131] \n",
      "Epoch [63/100]: 100%|██████████| 32/32 [00:00<00:00, 63.54it/s, loss=0.0128] \n",
      "Epoch [64/100]: 100%|██████████| 32/32 [00:00<00:00, 63.76it/s, loss=0.0122] \n",
      "Epoch [65/100]: 100%|██████████| 32/32 [00:00<00:00, 63.23it/s, loss=0.012]  \n",
      "Epoch [66/100]: 100%|██████████| 32/32 [00:00<00:00, 62.64it/s, loss=0.0117] \n",
      "Epoch [67/100]: 100%|██████████| 32/32 [00:00<00:00, 63.36it/s, loss=0.0114] \n",
      "Epoch [68/100]: 100%|██████████| 32/32 [00:00<00:00, 62.26it/s, loss=0.0111] \n",
      "Epoch [69/100]: 100%|██████████| 32/32 [00:00<00:00, 62.93it/s, loss=0.0111] \n",
      "Epoch [70/100]: 100%|██████████| 32/32 [00:00<00:00, 62.27it/s, loss=0.0108] \n",
      "Epoch [71/100]: 100%|██████████| 32/32 [00:00<00:00, 63.72it/s, loss=0.0105] \n",
      "Epoch [72/100]: 100%|██████████| 32/32 [00:00<00:00, 63.76it/s, loss=0.0104] \n",
      "Epoch [73/100]: 100%|██████████| 32/32 [00:00<00:00, 63.33it/s, loss=0.0102] \n",
      "Epoch [74/100]: 100%|██████████| 32/32 [00:00<00:00, 63.38it/s, loss=0.0102] \n",
      "Epoch [75/100]: 100%|██████████| 32/32 [00:00<00:00, 63.07it/s, loss=0.00995]\n",
      "Epoch [76/100]: 100%|██████████| 32/32 [00:00<00:00, 63.72it/s, loss=0.00977]\n",
      "Epoch [77/100]: 100%|██████████| 32/32 [00:00<00:00, 63.53it/s, loss=0.00958]\n",
      "Epoch [78/100]: 100%|██████████| 32/32 [00:00<00:00, 64.08it/s, loss=0.00958]\n",
      "Epoch [79/100]: 100%|██████████| 32/32 [00:00<00:00, 64.21it/s, loss=0.00939]\n",
      "Epoch [80/100]: 100%|██████████| 32/32 [00:00<00:00, 63.70it/s, loss=0.00929]\n",
      "Epoch [81/100]: 100%|██████████| 32/32 [00:00<00:00, 64.21it/s, loss=0.00909]\n",
      "Epoch [82/100]: 100%|██████████| 32/32 [00:00<00:00, 64.25it/s, loss=0.00908]\n",
      "Epoch [83/100]: 100%|██████████| 32/32 [00:00<00:00, 63.69it/s, loss=0.00909]\n",
      "Epoch [84/100]: 100%|██████████| 32/32 [00:00<00:00, 63.65it/s, loss=0.0089] \n",
      "Epoch [85/100]: 100%|██████████| 32/32 [00:00<00:00, 64.05it/s, loss=0.00881]\n",
      "Epoch [86/100]: 100%|██████████| 32/32 [00:00<00:00, 64.71it/s, loss=0.00878]\n",
      "Epoch [87/100]: 100%|██████████| 32/32 [00:00<00:00, 63.38it/s, loss=0.00878]\n",
      "Epoch [88/100]: 100%|██████████| 32/32 [00:00<00:00, 64.25it/s, loss=0.00864]\n",
      "Epoch [89/100]: 100%|██████████| 32/32 [00:00<00:00, 64.55it/s, loss=0.00856]\n",
      "Epoch [90/100]: 100%|██████████| 32/32 [00:00<00:00, 63.94it/s, loss=0.00857]\n",
      "Epoch [91/100]: 100%|██████████| 32/32 [00:00<00:00, 63.87it/s, loss=0.00855]\n",
      "Epoch [92/100]: 100%|██████████| 32/32 [00:00<00:00, 62.84it/s, loss=0.00849]\n",
      "Epoch [93/100]: 100%|██████████| 32/32 [00:00<00:00, 63.34it/s, loss=0.00858]\n",
      "Epoch [94/100]: 100%|██████████| 32/32 [00:00<00:00, 61.22it/s, loss=0.00844]\n",
      "Epoch [95/100]: 100%|██████████| 32/32 [00:00<00:00, 62.64it/s, loss=0.00848]\n",
      "Epoch [96/100]: 100%|██████████| 32/32 [00:00<00:00, 63.19it/s, loss=0.00846]\n",
      "Epoch [97/100]: 100%|██████████| 32/32 [00:00<00:00, 63.52it/s, loss=0.00846]\n",
      "Epoch [98/100]: 100%|██████████| 32/32 [00:00<00:00, 64.26it/s, loss=0.00841]\n",
      "Epoch [99/100]: 100%|██████████| 32/32 [00:00<00:00, 64.02it/s, loss=0.00853]\n",
      "Epoch [100/100]: 100%|██████████| 32/32 [00:00<00:00, 65.63it/s, loss=0.00852]\n",
      "100%|██████████| 263/263 [00:00<00:00, 321.39it/s]\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "p = argparse.ArgumentParser()\n",
    "p.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "p.add_argument('--gpu', type=str,default='0')\n",
    "p.add_argument('--seed', type=int, default=42)\n",
    "p.add_argument('--fp16', action=\"store_true\")\n",
    "# General training options\n",
    "p.add_argument('--batch_size', type=int, default=8000)\n",
    "p.add_argument('--lr', type=float, default=5e-5, help='learning rate. default=1e-4')\n",
    "p.add_argument('--num_epochs', type=int, default=200,\n",
    "               help='Number of epochs to train for.')\n",
    "p.add_argument('--checkpoint', type=int, default=100,\n",
    "               help='checkpoint is saved.')\n",
    "p.add_argument('--ckpt', type=str,default=\"/CoordNet/checkpoints/\",help='checkpoint path.')\n",
    "p.add_argument('--result_dir', type=str, default='./result/', metavar='N',\n",
    "                    help='the path where we stored the synthesized data')\n",
    "p.add_argument('--temporal', type=int, default=0, metavar='N')\n",
    "p.add_argument('--lr_s', type=str, default='cosine', help='learning rate scheduler')\n",
    "\n",
    "p.add_argument('--dataset', type=str, default='vortex')\n",
    "p.add_argument('--spatial', type=int, default=2, metavar='N')\n",
    "p.add_argument('--mode', type=str, default='train', metavar='N')\n",
    "# opt = p.parse_known_args()[0]\n",
    "opt = p.parse_args(args=[])\n",
    "\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = opt.gpu\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]  =  \"TRUE\"\n",
    "\n",
    "opt.cuda = not opt.no_cuda and torch.cuda.is_available()\n",
    "seed_everything(opt.seed)\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "def main():\n",
    "    print('FP16 enbled: ', opt.fp16)\n",
    "    Data = ScalarDataSet(opt)\n",
    "    Model = CoordNet(4,1,init_features=64, num_res=5)\n",
    "\n",
    "    if opt.mode in ['inf', 'ue']:\n",
    "        ckpt = './result/'+opt.dataset+opt.ckpt+'-'+str(opt.spatial)+'-'+str(opt.temporal)+'-'+str(opt.num_epochs)+'.pth'\n",
    "        Model.load_state_dict(torch.load(ckpt))\n",
    "    Model.cuda()\n",
    "\n",
    "    if opt.mode == 'train':\n",
    "        print('Initalize Model Successfully using Sine Function!')\n",
    "        trainNet(Model,opt,Data)\n",
    "        inf(Model, Data,opt)\n",
    "    elif opt.mode == 'inf':\n",
    "        inf(Model, Data,opt)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f99ae9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:41.776336669921875\n",
      "41.776336669921875\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "data_name = opt.dataset\n",
    "origin_dir = './dataset/' + data_name + '/'\n",
    "recons_dir = './result/' + data_name + '/CoordNet/outputs/'+str(opt.spatial)+'-'+str(opt.temporal)+'/'\n",
    "psnr,k = 0,0\n",
    "line = []\n",
    "psnr_fn_paper = lambda gt, pred, diff: 10. * torch.log10(diff**2 / torch.mean((gt-pred)**2))\n",
    "for i in range(1,2):\n",
    "    gt = np.fromfile(origin_dir + '{:04d}.raw'.format(i),dtype=np.float32)\n",
    "    \n",
    "    filename = f\"{i:04d}-CoordNet.raw\"\n",
    "    file_path = os.path.join(recons_dir, filename)\n",
    "    d = np.fromfile(file_path, dtype=np.float32)\n",
    "    \n",
    "    gt = 2*(gt-np.min(gt))/(np.max(gt)-np.min(gt))-1\n",
    "    d = torch.from_numpy(d)\n",
    "    gt = torch.from_numpy(gt)    \n",
    "    diff = gt.max() - gt.min()\n",
    "    \n",
    "    psnr_volume = psnr_fn_paper(gt, d, diff)\n",
    "    print(str(i)+\":\"+str(psnr_volume.item()))\n",
    "    line.append(psnr_volume.item())\n",
    "    psnr+=psnr_volume.item()\n",
    "    k+=1\n",
    "print(psnr/k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1525cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = opt.dataset\n",
    "origin_dir = './dataset/' + data_name + '/'\n",
    "recons_dir = './result/' + data_name + '/CoordNet/outputs/'+str(opt.spatial)+'-'+str(opt.temporal)+'/'\n",
    "\n",
    "for i in range(1,2):\n",
    "    filename = f\"{i:04d}-CoordNet.raw\"\n",
    "    file_path = os.path.join(recons_dir, filename)\n",
    "    d = np.fromfile(file_path, dtype=np.float32)\n",
    "    d[0] = -1.0\n",
    "    d[1] = 1.0\n",
    "    savename = f\"CoordNet.raw\"\n",
    "    d_path = os.path.join(recons_dir, savename)\n",
    "    d.astype(np.float32).tofile(d_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d16d5acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 11.8\n",
      "cuDNN version: 90100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"cuDNN version: {torch.backends.cudnn.version()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
